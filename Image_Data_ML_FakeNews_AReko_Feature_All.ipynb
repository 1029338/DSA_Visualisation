{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import display\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from __future__ import print_function\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17961, 138)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset \n",
    "url = \"1.5_ML_Data_NC_fake_articles_2100.csv\"\n",
    "names = [\"id\",\"Labels\",\"Class\",\"WC\",\"Analytic\",\"Clout\",\"Authentic\",\"Tone\",\"WPS\",\"Sixltr\",\"Dic\",\"function\",\"pronoun\",\"ppron\",\"i\",\"we\",\"you\",\"shehe\",\"they\",\"ipron\",\"article\",\"prep\",\"auxverb\",\"adverb\",\"conj\",\"negate\",\"verb\",\"adj\",\"compare\",\"interrog\",\"number\",\"quant\",\"affect\",\"posemo\",\"negemo\",\"anx\",\"anger\",\"sad\",\"social\",\"family\",\"friend\",\"female\",\"male\",\"cogproc\",\"insight\",\"cause\",\"discrep\",\"tentat\",\"certain\",\"differ\",\"percept\",\"see\",\"hear\",\"feel\",\"bio\",\"body\",\"health\",\"sexual\",\"ingest\",\"drives\",\"affiliation\",\"achieve\",\"power\",\"reward\",\"risk\",\"focuspast\",\"focuspresent\",\"focusfuture\",\"relativ\",\"motion\",\"space\",\"time\",\"work\",\"leisure\",\"home\",\"money\",\"relig\",\"death\",\"informal\",\"swear\",\"netspeak\",\"assent\",\"nonflu\",\"filler\",\"self_search_adult\",\"self_search_medical\",\"self_search_spoofed\",\"self_search_violence\",\"text_exist\",\"max_score\",\"score_red\",\"score_green\",\"score_blue\",\"max_frac\",\"frac_red\",\"frac_green\",\"frac_blue\",\"no_of_faces\",\"age\",\"gender\",\"gender_confidence\",\"face_quality_brightness\",\"face_quality_sharpness\",\"smile\",\"smile_confidence\",\"emotion_happy\",\"emotion_sad\",\"emotion_angry\",\"emotion_confused\",\"emotion_disgusted\",\"emotion_surprised\",\"emotion_calm\",\"emotion_unknown\",\"no_of_celebrity_faces\",\"celebrity_confidence\",\"celebrity_quality_brightness\",\"celebrity_quality_sharpness\",\"size\",\"width\",\"height\",\"sharpness\",\"contrast\",\"brightness\",\"color_dominant_r\",\"color_dominant_g\",\"color_dominant_b\",\"has_artificial\",\"has_natural\",\"topic_0\",\"topic_1\",\"topic_2\",\"topic_3\",\"topic_4\",\"topic_5\",\"topic_6\",\"topic_7\",\"topic_8\",\"topic_9\"]\n",
    "dataset = pd.read_csv(url, names=names,low_memory=False,skiprows=[0])\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073, 138)\n"
     ]
    }
   ],
   "source": [
    "fake_class_dataset = dataset.loc[dataset['Class'] == 'fake']\n",
    "print(fake_class_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15888, 138)\n"
     ]
    }
   ],
   "source": [
    "credible_class_dataset = dataset.loc[dataset['Class'] == 'credible']\n",
    "print(credible_class_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073, 138)\n"
     ]
    }
   ],
   "source": [
    "credible_class_dataset_sampled = credible_class_dataset.sample(n=2073)\n",
    "print(credible_class_dataset_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_class_dataset.to_csv('ML_Data_Sampled_Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4146, 138)\n"
     ]
    }
   ],
   "source": [
    "final_dataset = pd.concat([fake_class_dataset, credible_class_dataset_sampled])\n",
    "print(final_dataset.shape)\n",
    "#final_dataset.to_csv('ML_Data_Sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#array = final_dataset.values\n",
    "#X_both = array[:,2:137]\n",
    "#Y = array[:,0:2]\n",
    "\n",
    "#std_scaler = MinMaxScaler().fit(X_both)\n",
    "#X_both_scaled = std_scaler.transform(X_both)\n",
    "#print(X_both_scaled.shape)\n",
    "#print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.savetxt('ML_Data_Scaled_Sampled_1.csv',X_both_scaled,fmt='%.6f',delimiter=',',header='\"WC\",\"Analytic\",\"Clout\",\"Authentic\",\"Tone\",\"WPS\",\"Sixltr\",\"Dic\",\"function\",\"pronoun\",\"ppron\",\"i\",\"we\",\"you\",\"shehe\",\"they\",\"ipron\",\"article\",\"prep\",\"auxverb\",\"adverb\",\"conj\",\"negate\",\"verb\",\"adj\",\"compare\",\"interrog\",\"number\",\"quant\",\"affect\",\"posemo\",\"negemo\",\"anx\",\"anger\",\"sad\",\"social\",\"family\",\"friend\",\"female\",\"male\",\"cogproc\",\"insight\",\"cause\",\"discrep\",\"tentat\",\"certain\",\"differ\",\"percept\",\"see\",\"hear\",\"feel\",\"bio\",\"body\",\"health\",\"sexual\",\"ingest\",\"drives\",\"affiliation\",\"achieve\",\"power\",\"reward\",\"risk\",\"focuspast\",\"focuspresent\",\"focusfuture\",\"relativ\",\"motion\",\"space\",\"time\",\"work\",\"leisure\",\"home\",\"money\",\"relig\",\"death\",\"informal\",\"swear\",\"netspeak\",\"assent\",\"nonflu\",\"filler\",\"self_search_adult\",\"self_search_medical\",\"self_search_spoofed\",\"self_search_violence\",\"text_exist\",\"max_score\",\"score_red\",\"score_green\",\"score_blue\",\"max_frac\",\"frac_red\",\"frac_green\",\"frac_blue\",\"no_of_faces\",\"age\",\"gender\",\"gender_confidence\",\"face_quality_brightness\",\"face_quality_sharpness\",\"smile\",\"smile_confidence\",\"emotion_happy\",\"emotion_sad\",\"emotion_angry\",\"emotion_confused\",\"emotion_disgusted\",\"emotion_surprised\",\"emotion_calm\",\"emotion_unknown\",\"no_of_celebrity_faces\",\"celebrity_confidence\",\"celebrity_quality_brightness\",\"celebrity_quality_sharpness\",\"size\",\"width\",\"height\",\"sharpness\",\"contrast\",\"brightness\",\"color_dominant_r\",\"color_dominant_g\",\"color_dominant_b\",\"has_artificial\",\"has_natural\",\"topic_0\",\"topic_1\",\"topic_2\",\"topic_3\",\"topic_4\",\"topic_5\",\"topic_6\",\"topic_7\",\"topic_8\",\"topic_9\"')\n",
    "#np.savetxt('ML_Data_Scaled_Sampled_2.csv',Y[:,0],fmt='%s',delimiter=',', header='\"Labels\"' )\n",
    "#np.savetxt('ML_Data_Scaled_Sampled_3.csv',Y[:,1],fmt='%s',delimiter=',', header='\"Class\"' )\n",
    "#new_array = np.concatenate((Y,X_both_scaled),axis = 1)\n",
    "#print(new_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final_dataset_scaled = pd.DataFrame(data=new_array)\n",
    "#print(final_dataset_scaled.shape)\n",
    "#final_dataset_scaled.to_csv('ML_Data_Sampled_Standardized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4146, 138)\n",
      "(4146, 81)\n",
      "(4146, 54)\n",
      "(4146, 135)\n"
     ]
    }
   ],
   "source": [
    "# Split-out validation dataset\n",
    "array = final_dataset.values\n",
    "X_text = array[:,3:84]\n",
    "X_visual = array[:,84:138]\n",
    "X_both = array[:,3:138]\n",
    "Y = array[:,2]\n",
    "\n",
    "print(array.shape)\n",
    "print(X_text.shape)\n",
    "print(X_visual.shape)\n",
    "print(X_both.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2902, 81)\n",
      "(2902, 54)\n",
      "(2902, 135)\n",
      "(2902,)\n"
     ]
    }
   ],
   "source": [
    "validation_size = 0.30\n",
    "seed = 7\n",
    "\n",
    "X_text_train, X_text_validation, Y_text_train, Y_text_validation = model_selection.train_test_split(X_text, Y, test_size=validation_size, random_state=seed)\n",
    "X_visual_train, X_visual_validation, Y_visual_train, Y_visual_validation = model_selection.train_test_split(X_visual, Y, test_size=validation_size, random_state=seed)\n",
    "X_both_train, X_both_validation, Y_both_train, Y_both_validation = model_selection.train_test_split(X_both, Y, test_size=validation_size, random_state=seed)\n",
    "print(X_text_train.shape)\n",
    "print(X_visual_train.shape)\n",
    "print(X_both_train.shape)\n",
    "print(Y_both_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2902, 81)\n",
      "(1244, 81)\n"
     ]
    }
   ],
   "source": [
    "#std_scale = preprocessing.StandardScaler().fit(X_text_train)\n",
    "#X_text_train = std_scale.transform(X_text_train)\n",
    "#X_text_validation = std_scale.transform(X_text_validation)\n",
    "\n",
    "std_scaler = MinMaxScaler().fit(X_text_train)\n",
    "X_text_train = std_scaler.transform(X_text_train)\n",
    "X_text_validation = std_scaler.transform(X_text_validation)\n",
    "\n",
    "#std_scale = preprocessing.StandardScaler().fit(X_visual_train)\n",
    "#X_visual_train = std_scale.transform(X_visual_train)\n",
    "#X_visual_validation = std_scale.transform(X_visual_validation)\n",
    "\n",
    "std_scaler = MinMaxScaler().fit(X_visual_train)\n",
    "X_visual_train = std_scaler.transform(X_visual_train)\n",
    "X_visual_validation = std_scaler.transform(X_visual_validation)\n",
    "\n",
    "#std_scale = preprocessing.StandardScaler().fit(X_both_train)\n",
    "#X_both_train = std_scale.transform(X_both_train)\n",
    "#X_both_validation = std_scale.transform(X_both_validation)\n",
    "\n",
    "std_scaler = MinMaxScaler().fit(X_both_train)\n",
    "X_both_train = std_scaler.transform(X_both_train)\n",
    "X_both_validation = std_scaler.transform(X_both_validation)\n",
    "\n",
    "print(X_text_train.shape)\n",
    "print(X_text_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "def getProperDataForTraining(no):\n",
    "    if(no == 0):\n",
    "        return X_text_train, Y_text_train\n",
    "    elif(no == 1):\n",
    "        return X_visual_train, Y_visual_train\n",
    "    else:\n",
    "        return X_both_train, Y_both_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "[0.83701267922739642, 0.85664296717620569, 0.87904017063633122]\n",
      "[0.98414741083066715, 0.74430738239127858, 0.94899751155350154]\n",
      "[0.94589880317573183, 0.85802820239364852, 0.96451238298376585]\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "models_at_each_i = []\n",
    "model_with_text = []\n",
    "model_with_visual = []\n",
    "model_with_both = []\n",
    "\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    training_x, training_y = getProperDataForTraining(i)\n",
    "    models = []\n",
    "    #models.append(('LR', LogisticRegression()))\n",
    "    #models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    #models.append(('KNN', KNeighborsClassifier()))\n",
    "    models.append(('CART', DecisionTreeClassifier()))\n",
    "    #models.append(('NB', GaussianNB()))\n",
    "    models.append(('SVM', SVC()))\n",
    "    models.append(('RF', RandomForestClassifier()))\n",
    "    # evaluate each model in turn\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "        cv_results = model_selection.cross_val_score(model, training_x, training_y, cv=kfold, scoring=scoring)\n",
    "        #print(cv_results)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        #print(msg)\n",
    "        if(i == 0):\n",
    "            model_with_text.append(cv_results.mean())\n",
    "        elif(i == 1):\n",
    "            model_with_visual.append(cv_results.mean())\n",
    "        elif(i == 2):\n",
    "            model_with_both.append(cv_results.mean())\n",
    "    models_at_each_i.append(models)\n",
    "print(model_with_text)\n",
    "print(model_with_visual)\n",
    "print(model_with_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getProperDataForValidation(no):\n",
    "    if(no == 0):\n",
    "        return X_text_validation, Y_text_validation\n",
    "    elif(no == 1):\n",
    "        return X_visual_validation, Y_visual_validation\n",
    "    else:\n",
    "        return X_both_validation, Y_both_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iteration 1\n",
      "0.833601286174\n",
      "[[522  95]\n",
      " [112 515]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   credible       0.82      0.85      0.83       617\n",
      "       fake       0.84      0.82      0.83       627\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1244\n",
      "\n",
      "1\n",
      "Iteration 2\n",
      "0.983118971061\n",
      "[[608   9]\n",
      " [ 12 615]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   credible       0.98      0.99      0.98       617\n",
      "       fake       0.99      0.98      0.98       627\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1244\n",
      "\n",
      "2\n",
      "Iteration 3\n",
      "0.934083601286\n",
      "[[577  40]\n",
      " [ 42 585]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   credible       0.93      0.94      0.93       617\n",
      "       fake       0.94      0.93      0.93       627\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset#store_covariance='true'\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    training_x, training_y = getProperDataForTraining(i)\n",
    "    validation_x, validation_y = getProperDataForValidation(i)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(training_x, training_y)\n",
    "    predictions_dtc = dtc.predict(validation_x)\n",
    "    print(\"Iteration \"+str(i+1))\n",
    "    print(accuracy_score(validation_y, predictions_dtc))\n",
    "    print(confusion_matrix(validation_y, predictions_dtc))\n",
    "    print(classification_report(validation_y, predictions_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "0.850482315113\n",
      "[[538  79]\n",
      " [107 520]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   credible       0.83      0.87      0.85       617\n",
      "       fake       0.87      0.83      0.85       627\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1244\n",
      "\n",
      "Iteration 2\n",
      "0.716237942122\n",
      "[[468 149]\n",
      " [204 423]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   credible       0.70      0.76      0.73       617\n",
      "       fake       0.74      0.67      0.71       627\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1244\n",
      "\n",
      "Iteration 3\n",
      "0.845659163987\n",
      "[[541  76]\n",
      " [116 511]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   credible       0.82      0.88      0.85       617\n",
      "       fake       0.87      0.81      0.84       627\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset#store_covariance='true'\n",
    "for i in range(3):\n",
    "    training_x, training_y = getProperDataForTraining(i)\n",
    "    validation_x, validation_y = getProperDataForValidation(i)\n",
    "    svc = SVC(probability=True)\n",
    "    svc.fit(training_x, training_y)\n",
    "    predictions_svc = svc.predict(validation_x)\n",
    "    print(\"Iteration \"+str(i+1))\n",
    "    print(accuracy_score(validation_y, predictions_svc))\n",
    "    print(confusion_matrix(validation_y, predictions_svc))\n",
    "    print(classification_report(validation_y, predictions_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "0.909967845659\n",
      "[[563  54]\n",
      " [ 58 569]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   credible       0.91      0.91      0.91       617\n",
      "       fake       0.91      0.91      0.91       627\n",
      "\n",
      "avg / total       0.91      0.91      0.91      1244\n",
      "\n",
      "Iteration 2\n",
      "0.963826366559\n",
      "[[579  38]\n",
      " [  7 620]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   credible       0.99      0.94      0.96       617\n",
      "       fake       0.94      0.99      0.96       627\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1244\n",
      "\n",
      "Iteration 3\n",
      "0.971061093248\n",
      "[[586  31]\n",
      " [  5 622]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   credible       0.99      0.95      0.97       617\n",
      "       fake       0.95      0.99      0.97       627\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#store_covariance='true'\n",
    "rf_models = []\n",
    "rf_models_predictions_probabilities = []\n",
    "for i in range(3):\n",
    "    training_x, training_y = getProperDataForTraining(i)\n",
    "    validation_x, validation_y = getProperDataForValidation(i)\n",
    "    rf = RandomForestClassifier(n_estimators=250,random_state=0)\n",
    "    rf.fit(training_x, training_y)\n",
    "    predictions = rf.predict(validation_x)\n",
    "    predictions_probability = rf.predict_proba(validation_x)\n",
    "    rf_models.append(rf)\n",
    "    rf_models_predictions_probabilities.append(predictions_probability)\n",
    "    print(\"Iteration \"+str(i+1))\n",
    "    print(accuracy_score(validation_y, predictions))\n",
    "    print(confusion_matrix(validation_y, predictions))\n",
    "    print(classification_report(validation_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_x, training_y = getProperDataForTraining(1)\n",
    "validation_x, validation_y = getProperDataForValidation(1)\n",
    "#print(validation_x[0])\n",
    "num = 150\n",
    "class_names = ['credible', 'fake']\n",
    "indices_name = [\"WC\",\"Analytic\",\"Clout\",\"Authentic\",\"Tone\",\"WPS\",\"Sixltr\",\"Dic\",\"function\",\"pronoun\",\"ppron\",\"i\",\"we\",\"you\",\"shehe\",\"they\",\"ipron\",\"article\",\"prep\",\"auxverb\",\"adverb\",\"conj\",\"negate\",\"verb\",\"adj\",\"compare\",\"interrog\",\"number\",\"quant\",\"affect\",\"posemo\",\"negemo\",\"anx\",\"anger\",\"sad\",\"social\",\"family\",\"friend\",\"female\",\"male\",\"cogproc\",\"insight\",\"cause\",\"discrep\",\"tentat\",\"certain\",\"differ\",\"percept\",\"see\",\"hear\",\"feel\",\"bio\",\"body\",\"health\",\"sexual\",\"ingest\",\"drives\",\"affiliation\",\"achieve\",\"power\",\"reward\",\"risk\",\"focuspast\",\"focuspresent\",\"focusfuture\",\"relativ\",\"motion\",\"space\",\"time\",\"work\",\"leisure\",\"home\",\"money\",\"relig\",\"death\",\"informal\",\"swear\",\"netspeak\",\"assent\",\"nonflu\",\"filler\",\"self_search_adult\",\"self_search_medical\",\"self_search_spoofed\",\"self_search_violence\",\"text_exist\",\"max_score\",\"score_red\",\"score_green\",\"score_blue\",\"max_frac\",\"frac_red\",\"frac_green\",\"frac_blue\",\"no_of_faces\",\"age\",\"gender\",\"gender_confidence\",\"face_quality_brightness\",\"face_quality_sharpness\",\"smile\",\"smile_confidence\",\"emotion_happy\",\"emotion_sad\",\"emotion_angry\",\"emotion_confused\",\"emotion_disgusted\",\"emotion_surprised\",\"emotion_calm\",\"emotion_unknown\",\"no_of_celebrity_faces\",\"celebrity_confidence\",\"celebrity_quality_brightness\",\"celebrity_quality_sharpness\",\"topic_0\",\"topic_1\",\"topic_2\",\"topic_3\",\"topic_4\",\"topic_5\",\"topic_6\",\"topic_7\",\"topic_8\",\"topic_9\"]\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(training_x, feature_names=indices_name, class_names=class_names,\n",
    "                                                   discretize_continuous=True)\n",
    "exp = explainer.explain_instance(validation_x[num], rf_models[1].predict_proba, num_features=20, top_labels=1)\n",
    "exp.show_in_notebook(show_table=True, show_all=False)\n",
    "\n",
    "print('Document id: %d' % num)\n",
    "print(rf_models_predictions_probabilities[1][num])\n",
    "print('True class: %s' % validation_y[num])\n",
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(8,8)).clf()\n",
    "model_name = ['Textual','Visual','Textual+Visual']\n",
    "for idx in range(3):\n",
    "    validation_x, validation_y = getProperDataForValidation(idx)\n",
    "    true_prob_validation_y = label_binarize(validation_y, classes=['fake','credible'])\n",
    "    predict_prob_validation_y = rf_models_predictions_probabilities[idx]\n",
    "    positive_class_predict_prob_valid_y = predict_prob_validation_y[:,0]\n",
    "    roc_score = roc_auc_score(true_prob_validation_y, positive_class_predict_prob_valid_y,average='micro')\n",
    "    print(roc_score)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(1):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true_prob_validation_y, positive_class_predict_prob_valid_y)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(true_prob_validation_y.ravel(), positive_class_predict_prob_valid_y.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    print(roc_auc)\n",
    "    lw = 2\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], \n",
    "             #color='darkorange',\n",
    "             lw=lw, label='%s - ROC curve (area = %0.2f)' % (model_name[idx], roc_auc[0]))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#indices_name = [\"WC\",\"Analytic\",\"Clout\",\"Authentic\",\"Tone\",\"WPS\",\"Sixltr\",\"Dic\",\"function\",\"pronoun\",\"ppron\",\"i\",\"we\",\"you\",\"shehe\",\"they\",\"ipron\",\"article\",\"prep\",\"auxverb\",\"adverb\",\"conj\",\"negate\",\"verb\",\"adj\",\"compare\",\"interrog\",\"number\",\"quant\",\"affect\",\"posemo\",\"negemo\",\"anx\",\"anger\",\"sad\",\"social\",\"family\",\"friend\",\"female\",\"male\",\"cogproc\",\"insight\",\"cause\",\"discrep\",\"tentat\",\"certain\",\"differ\",\"percept\",\"see\",\"hear\",\"feel\",\"bio\",\"body\",\"health\",\"sexual\",\"ingest\",\"drives\",\"affiliation\",\"achieve\",\"power\",\"reward\",\"risk\",\"focuspast\",\"focuspresent\",\"focusfuture\",\"relativ\",\"motion\",\"space\",\"time\",\"work\",\"leisure\",\"home\",\"money\",\"relig\",\"death\",\"informal\",\"swear\",\"netspeak\",\"assent\",\"nonflu\",\"filler\"]\n",
    "#indices_name = [\"num_faces\",\"white\",\"american indian or alaska native\",\"asian\",\"hispanic or latino or spanish origin\",\"middle eastern or north african\",\"black or african american\",\"native hawaiian or pacific islander\",\"age\",\"masculine\",\"feminine\",\"topic_0\",\"topic_1\",\"topic_2\",\"topic_3\",\"topic_4\",\"topic_5\",\"topic_6\",\"topic_7\",\"topic_8\",\"topic_9\"]\n",
    "indices_name = [\"WC\",\"Analytic\",\"Clout\",\"Authentic\",\"Tone\",\"WPS\",\"Sixltr\",\"Dic\",\"function\",\"pronoun\",\"ppron\",\"i\",\"we\",\"you\",\"shehe\",\"they\",\"ipron\",\"article\",\"prep\",\"auxverb\",\"adverb\",\"conj\",\"negate\",\"verb\",\"adj\",\"compare\",\"interrog\",\"number\",\"quant\",\"affect\",\"posemo\",\"negemo\",\"anx\",\"anger\",\"sad\",\"social\",\"family\",\"friend\",\"female\",\"male\",\"cogproc\",\"insight\",\"cause\",\"discrep\",\"tentat\",\"certain\",\"differ\",\"percept\",\"see\",\"hear\",\"feel\",\"bio\",\"body\",\"health\",\"sexual\",\"ingest\",\"drives\",\"affiliation\",\"achieve\",\"power\",\"reward\",\"risk\",\"focuspast\",\"focuspresent\",\"focusfuture\",\"relativ\",\"motion\",\"space\",\"time\",\"work\",\"leisure\",\"home\",\"money\",\"relig\",\"death\",\"informal\",\"swear\",\"netspeak\",\"assent\",\"nonflu\",\"filler\",\"self_search_adult\",\"self_search_medical\",\"self_search_spoofed\",\"self_search_violence\",\"text_exist\",\"max_score\",\"score_red\",\"score_green\",\"score_blue\",\"max_frac\",\"frac_red\",\"frac_green\",\"frac_blue\",\"no_of_faces\",\"age\",\"gender\",\"gender_confidence\",\"face_quality_brightness\",\"face_quality_sharpness\",\"smile\",\"smile_confidence\",\"emotion_happy\",\"emotion_sad\",\"emotion_angry\",\"emotion_confused\",\"emotion_disgusted\",\"emotion_surprised\",\"emotion_calm\",\"emotion_unknown\",\"no_of_celebrity_faces\",\"celebrity_confidence\",\"celebrity_quality_brightness\",\"celebrity_quality_sharpness\",\"size\",\"width\",\"height\",\"sharpness\",\"contrast\",\"brightness\",\"color_dominant_r\",\"color_dominant_g\",\"color_dominant_b\",\"has_artificial\",\"has_natural\",\"topic_0\",\"topic_1\",\"topic_2\",\"topic_3\",\"topic_4\",\"topic_5\",\"topic_6\",\"topic_7\",\"topic_8\",\"topic_9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = rf_models[2].feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the feature ranking\n",
    "indices_name_sorted = []\n",
    "for f in range(len(indices_name)):\n",
    "    #print(\"%d. %s (%f)\" % (f + 1, indices_name[indices[f]], importances[indices[f]]))\n",
    "    indices_name_sorted.append(indices_name[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices_name)), importances[indices],\n",
    "       color=\"g\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(len(indices_name)), indices_name_sorted,rotation=90)\n",
    "plt.xlim([-1, len(indices_name)])\n",
    "#fig.savefig('test.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on validation dataset\n",
    "results\n",
    "lr = LogisticRegression()#store_covariance='true'\n",
    "lr.fit(X_train_std, Y_train)\n",
    "predictions_lr = lr.predict(X_validation_std)\n",
    "print(accuracy_score(Y_validation, predictions_lr))\n",
    "print(confusion_matrix(Y_validation, predictions_lr))\n",
    "print(classification_report(Y_validation, predictions_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on validation dataset\n",
    "lda = LinearDiscriminantAnalysis()#store_covariance='true'\n",
    "lda.fit(X_train_std, Y_train)\n",
    "predictions_lda = lda.predict(X_validation_std)\n",
    "print(accuracy_score(Y_validation, predictions_lda))\n",
    "print(confusion_matrix(Y_validation, predictions_lda))\n",
    "print(classification_report(Y_validation, predictions_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on validation dataset\n",
    "nb = GaussianNB()#store_covariance='true'\n",
    "nb.fit(X_train_std, Y_train)\n",
    "predictions_nb = nb.predict(X_validation_std)\n",
    "print(accuracy_score(Y_validation, predictions_nb))\n",
    "print(confusion_matrix(Y_validation, predictions_nb))\n",
    "print(classification_report(Y_validation, predictions_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()#store_covariance='true'\n",
    "knn.fit(X_train_std, Y_train)\n",
    "predictions_knn = knn.predict(X_validation_std)\n",
    "print(accuracy_score(Y_validation, predictions_knn))\n",
    "print(confusion_matrix(Y_validation, predictions_knn))\n",
    "print(classification_report(Y_validation, predictions_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "np.savetxt('ML_Data/traning.csv',X_train_std,fmt='%.2f',delimiter=',',header=\"'WC',\t'Analytic',\t'Clout',\t'Authentic',\t'Tone',\t'WPS',\t'Sixltr',\t'Dic',\t'function',\t'pronoun',\t'ppron',\t'i',\t'we',\t'you',\t'shehe',\t'they',\t'ipron',\t'article',\t'prep',\t'auxverb',\t'adverb',\t'conj',\t'negate',\t'verb',\t'adj',\t'compare',\t'interrog',\t'number',\t'quant',\t'affect',\t'posemo',\t'negemo',\t'anx',\t'anger',\t'sad',\t'social',\t'family',\t'friend',\t'female',\t'male',\t'cogproc',\t'insight',\t'cause',\t'discrep',\t'tentat',\t'certain',\t'differ',\t'percept',\t'see',\t'hear',\t'feel',\t'bio',\t'body',\t'health',\t'sexual',\t'ingest',\t'drives',\t'affiliation',\t'achieve',\t'power',\t'reward',\t'risk',\t'focuspast',\t'focuspresent',\t'focusfuture',\t'relativ',\t'motion',\t'space',\t'time',\t'work',\t'leisure',\t'home',\t'money',\t'relig',\t'death',\t'informal',\t'swear',\t'netspeak',\t'assent',\t'nonflu',\t'filler'\")\n",
    "np.savetxt('ML_Data/trainingLables.csv',Y_train,fmt='%s',delimiter=',', header=\" #Class\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
